# **Kaggle-Competitions**

## **Competition 1 (Analysing Titanic Survival)**
### **In this competition the goal is to predict the titanic survival. First I have analyze the data, then secondly I have clean the data, visualize the data and then normalize the data and apply machine learning unsupervised algorithms because it is a classification problem. I have also used K-fold technique to check which Algorithm is giving best accuracy. So, in this project I have used the following machine learning models:**
### **1. Logistic Regression**
### **2. Super Vector Machine**
### **3. Perceptron**
### **4. SGDClassifier**
### **5. Random Forest Classifier**
### **6. KNeighbors Classifier**
### **7. Decision Tree Classifier**
### **8. Linear SVC**
### **9. Naive Bayes**
### **10. CatBoost**
https://user-images.githubusercontent.com/90540916/157308819-0898be9f-cec7-40a5-965c-4c29665281a4.mp4


## **Competition 2 (House Price Prediction)**
### **In this project the goal is to predict the houses price. First I have analyze the data, then then secondly I have clean the data, visualize the data and then normalize the data and apply machine learning supervised algorithms because it is the regression problem. I have also used cross validation score for selecting the best model. So, in this project. I have used the following machine learning models:**
### **1. Decision Tree Regressor**
### **2. Random Forest Regressor**
### **3. XGBoost Rregressor**
https://user-images.githubusercontent.com/90540916/157314413-a1c021da-92e3-475f-ab56-65a1f079b6ed.mp4

